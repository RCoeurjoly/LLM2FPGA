takentaal-amendment v1.0

* TODO_NEXT LLM2FPGA [65%]
:PROPERTIES:
:COOKIE_DATA: todo recursive
:END:
- State "TODO_NEXT"  from              [2026-01-27 Tue 10:54]
LLM2FPGA aims to enable local inference of open-source Large Language Models (LLMs) on FPGAs using a fully open-source toolchain. While LLM inference has been demonstrated on proprietary hardware and software, we are not aware of any widely recognized project running open-source LLMs on FPGAs through a fully open-source EDA (Electronics Design Automation) flow. To fill this gap, the project will produce an HDL implementation of a lightweight open-source LLM, verify it via simulation, and then attempt synthesis and place-and-route on freely supported FPGA devices. By providing a fully open alternative to proprietary and cloud-based LLM inference, LLM2FPGA will offer a transparent, flexible, and privacy-friendly way to run your own LLM on local hardware.
** DONE Survey & candidate selection
CLOSED: [2026-01-27 Tue 10:55]
- State "DONE"       from "TODO_NEXT"  [2026-01-27 Tue 10:55]
- State "TODO_NEXT"  from              [2026-01-27 Tue 10:54]
State of the art review. Although some candidate projects have been identified, to have the big picture of what has been achieved so far, we need to understand 10 to 15 papers/projects, and what can be reused, even finding synergies between papers/projects.



We are lucky that the keywords LLM and FPGA usually give highly relevant results.



The first subtask is desk research. Survey table of 10+ FPGA-LLM papers/repos, answering the following questions:



Openness: Is the code or detailed design public or promised? Open to open-source FPGA tools? Uses open LLMs?



Hardware: Avoid if it needs extra hardware. Check FPGA and open toolchain support.



Design: Note method (RTL/HLS), model size (<10M preferred), proof-of-concept potential, and proprietary tool dependencies.



Second subtask:



The purpose is to identify issues or blockages, not to get each project completely reproduced.



— Can the HDL (SystemVerilog, Verilog) be parsed by Yosys or yosys-slang?



— If HLS is used, can the original C/C++ code be compiled with Vericert or another FOSS HLS tool?



Issues or blockages such as:



— Uses features of HDL (SystemVerilog, VHDL) that are not supported in yosys.



In yosys, Verilog support is more mature than SystemVerilog (with yosys-slang) or VHDL (with ghdl-yosys-plugin)



— Same for HLS



The third subtask:



— Chosen kernel + why



— Any major blockers found in other candidates



— Fallback plan in case current kernel becomes unviable



From now on, we call the chosen kernel the *selected route*.



- Publish survey results based on desk research.

- Research compatibility of potential projects with open source tooling: create a script that clones each repo and runs elaboration with Yosys; logs archived (green, blockages etc)

- Write up and publish results of the research and next steps. (chosen kernel and why + fallback)

** DONE End-to-End semantic equivalence of a PyTorch kernel to synthesizable RTL [10/10]
CLOSED: [2026-01-28 Wed 11:37]
- State "DONE"       from "TODO_NEXT"  [2026-01-28 Wed 11:37]
- State "TODO_NEXT"  from              [2026-01-27 Tue 10:54]
*** DONE Title
CLOSED: [2026-01-27 Tue 14:01]
- State "DONE"       from "TODO_NEXT"  [2026-01-27 Tue 14:01]
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:53]
*** DONE Goal:
CLOSED: [2026-01-27 Tue 12:52]
- State "DONE"       from "TODO_NEXT"  [2026-01-27 Tue 12:52]
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:06]
Establish that the pipeline selected in Task 1 lowers a minimal PyTorch model (matrix multiplication kernel) to synthesizable RTL that is functionally equivalent to the input PyTorch.
*** DONE Risks and mitigations
CLOSED: [2026-01-28 Wed 11:37]
- State "DONE"       from "TODO_NEXT"  [2026-01-28 Wed 11:37]
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:43]
  PyTorch hard to simulate: it seems well documented https://docs.pytorch.org/executorch/stable/getting-started.html
  Discrepancy between PyTorch and RTL simulation: simulate each MLIR stage with original PyTorch, to isolate the pass that creates discrepancy
*** DONE Subtasks [5/5]
CLOSED: [2026-01-28 Wed 11:37]
- State "DONE"       from "TODO_NEXT"  [2026-01-28 Wed 11:37]
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:06]
**** DONE Subtask 1 consists of:
CLOSED: [2026-01-27 Tue 13:07]
- State "DONE"       from "TODO_NEXT"  [2026-01-27 Tue 13:07]
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:07]
flake.nix with all relevant tooling: torch-MLIR, LLVM MLIR, CIRCT, yosys.

Nix devshell provides all tools used by the pipeline.

Cached derivations for each pipeline stage, so reruns do not recompute earlier stages.

Devshell supports local debug builds for torch-mlir / LLVM / CIRCT / Yosys when Nix debug-symbol packaging is insufficient; instructions included.

**** DONE Subtask 2 consists of:
CLOSED: [2026-01-27 Tue 13:07]
- State "DONE"       from "TODO_NEXT"  [2026-01-27 Tue 13:07]
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:07]
With the same PyTorch module used in 1.c, run a PyTorch simulation with fixed inputs. Run pipeline with that model, simulate resulting SystemVerilog and compare with golden reference.
**** DONE Subtask 3 consists of:
CLOSED: [2026-01-27 Tue 16:31]
- State "DONE"       from "TODO_NEXT"  [2026-01-27 Tue 16:31]
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:07]
  Yosys ingestion + RTLIL netlist gate

Artifact: matmul.il produced by Yosys from matmul.sv.

Yosys completes elaboration and emits RTLIL without fatal errors.

**** DONE Subtask 4 consists of:
CLOSED: [2026-01-27 Tue 16:32]
- State "DONE"       from "TODO_NEXT"  [2026-01-27 Tue 16:32]
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:07]
Glue RTL for interface, Bitstream generation and testing
Think of the simplest way to interface with the world, generate bitstream of glue RTL + model RTL, test results are equivalent to golden reference
**** DONE Subtask 5 consists of:
CLOSED: [2026-01-28 Wed 11:17]
- State "DONE"       from "TODO_NEXT"  [2026-01-28 Wed 11:17]
- State "TODO_NEXT"  from "DONE"       [2026-01-28 Wed 11:17]
- State "DONE"       from "TODO_NEXT"  [2026-01-27 Tue 16:32]
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:07]
Report and demo of results
*** DONE Deliverables
CLOSED: [2026-01-28 Wed 11:37]
- State "DONE"       from "TODO_NEXT"  [2026-01-28 Wed 11:37]
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:07]
- nix flake and matmul.sv from executing it

- PyTorch simulation trace, systemverilog testbench and their comparison

- matmul.il and resource usage report with "yosys stat"

- bitstream
  
- Write up of results, and video demo if succesful

** TODO_NEXT Lowering of small LLM to RTL [7/10]
- State "TODO_NEXT"  from              [2026-01-27 Tue 10:54]
*** DONE Title
CLOSED: [2026-01-27 Tue 12:54]
- State "DONE"       from "TODO_NEXT"  [2026-01-27 Tue 12:54]
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:53]

*** DONE Goal:
CLOSED: [2026-01-27 Tue 14:04]
- State "DONE"       from "TODO_NEXT"  [2026-01-27 Tue 14:04]
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:09]
Test if a small open-source language model (TinyStories-1M) can be lowered from PyTorch to synthesizable RTL using a fully open-source compilation flow.

In this task we move from small matmul module to smallest available LLM.
This task establishes existence of a valid lowering path only; scalability and hardware execution are out of scope, for later tasks.
*** DONE Risks and mitigation
CLOSED: [2026-01-28 Wed 13:07]
- State "DONE"       from "TODO_NEXT"  [2026-01-28 Wed 13:07]
- State "TODO_NEXT"  from "DONE"       [2026-01-28 Wed 13:01]
- State "DONE"       from "TODO_NEXT"  [2026-01-27 Tue 16:33]
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:09]
Unsupported MLIR operators

Invalid or non-synthesizable RTL emitted

Excessive compile times due to pass ordering or repeated transformations

Mitigation includes reduction of failing MLIR programs using mlir-reduce, local pass reordering or stubbing, and isolating minimal reproducing cases. Upstream contributions may be prepared but are not required for task completion.

Debugging MLIR: https://mlir.llvm.org/getting_started/Debugging/

*** TODO_NEXT Subtasks
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:43]
**** DONE Subtask 1
CLOSED: [2026-01-28 Wed 11:51]
- State "DONE"       from "TODO_NEXT"  [2026-01-28 Wed 11:51]
- State "TODO_NEXT"  from              [2026-01-28 Wed 11:49]
Frozen TinyStories-1M artifact
**** DONE Subtask 2
CLOSED: [2026-01-28 Wed 12:58]
- State "DONE"       from              [2026-01-28 Wed 12:58]
tiny_stories_1m.mlir, just before consumption by CIRCT
**** DONE Subtask 3
CLOSED: [2026-01-28 Wed 13:07]
- State "DONE"       from              [2026-01-28 Wed 13:07]
tiny_stories_1m.sv, generated by CIRCT
**** DONE Subtask 4
CLOSED: [2026-01-28 Wed 15:38]
- State "DONE"       from "TODO_NEXT"  [2026-01-28 Wed 15:38]
- State "TODO_NEXT"  from              [2026-01-28 Wed 13:07]
  Artifact: tinystories_1m.il produced by Yosys from tinystories_1m.sv.
  Yosys completes elaboration/flattening and emits RTLIL without fatal errors.
**** TODO_NEXT Subtask 5
- State "TODO_NEXT"  from              [2026-01-28 Wed 15:38]
  
*** TODO_NEXT Deliverables
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:43]
  - TinyStories-1M PyTorch model
  - tiny_stories_1m.mlir, just before consumption by CIRCT
  - tiny_stories_1m.sv, generated by CIRCT
  - tiny_stories_1m.il, generated by yosys
** TODO_NEXT System integration and hardware demonstration [2/5]
- State "TODO_NEXT"  from              [2026-01-27 Tue 10:54]
*** DONE Title
CLOSED: [2026-01-27 Tue 16:07]
- State "DONE"       from "TODO_NEXT"  [2026-01-27 Tue 16:07]
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:53]
*** DONE Goal:
CLOSED: [2026-01-27 Tue 16:07]
- State "DONE"       from "TODO_NEXT"  [2026-01-27 Tue 16:07]
- State "TODO_NEXT"  from "DONE"       [2026-01-27 Tue 16:02]
- State "DONE"       from "TODO_NEXT"  [2026-01-27 Tue 12:59]
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:09]
Demonstrate that the generated model RTL can coexist with minimal glue logic and be processed through a full FPGA synthesis and place-and-route flow.
Demonstrate execution of the synthesized design on FPGA hardware.
*** TODO_NEXT Risks and mitigations
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:10]
Non-idiomatic or impractical auto-generated interfaces


Incorrect results due to transformation errors in the compilation pipeline

Difficulty isolating faults across passes.

Mitigation consists of treating the PyTorch model as the single source of truth and introducing reference checks at every stage of the pipeline. For each MLIR, and RTL simulation.
*** TODO_NEXT Subtasks
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:10]
*** TODO_NEXT Deliverables
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:43]
** TODO_NEXT Scaling and resource usage analysis [2/5]
- State "TODO_NEXT"  from              [2026-01-27 Tue 10:54]
*** DONE Title
CLOSED: [2026-01-27 Tue 12:54]
- State "DONE"       from "TODO_NEXT"  [2026-01-27 Tue 12:54]
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:53]

*** DONE Goal:
CLOSED: [2026-01-27 Tue 13:00]
- State "DONE"       from "TODO_NEXT"  [2026-01-27 Tue 13:00]
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:43]
Measure how FPGA resource usage scales with model depth and width by mechanically scaling the validated TinyStories-1M architecture.

No new model architectures are introduced.

*** TODO_NEXT Risks and mitigations
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:44]
*** TODO_NEXT Subtasks
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:43]
*** TODO_NEXT Deliverables
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:43]
** TODO_NEXT Resource usage reduction strategies [6/8]
- State "TODO_NEXT"  from              [2026-01-27 Tue 10:55]
*** DONE Title
CLOSED: [2026-01-27 Tue 12:54]
- State "DONE"       from "TODO_NEXT"  [2026-01-27 Tue 12:54]
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:53]

*** DONE Goal:
CLOSED: [2026-01-27 Tue 13:00]
- State "DONE"       from "TODO_NEXT"  [2026-01-27 Tue 13:00]
- State "TODO_NEXT"  from              [2026-01-27 Tue 11:49]
Evaluate whether mitigation techniques can reduce resource usage if scaling results are negative.
*** TODO_NEXT Risks and mitigations
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:44]
No resource reduction.

Mitigation: testing and comparing several strategies, and documenting even the negative results.
*** DONE Subtasks
CLOSED: [2026-01-27 Tue 13:42]
- State "DONE"       from "TODO_NEXT"  [2026-01-27 Tue 13:42]
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:44]
**** DONE Subtask 1
CLOSED: [2026-01-27 Tue 13:42]
- State "DONE"       from "TODO_NEXT"  [2026-01-27 Tue 13:42]
- State "TODO_NEXT"  from              [2026-01-27 Tue 13:35]
Survey 5 to 10 mitigation strategies, at all levels of the pipeline: quantization at PyTorch level, eqmap at verilog level, mlir optimizations etc
**** DONE Subtask 2
CLOSED: [2026-01-27 Tue 13:42]
- State "DONE"       from              [2026-01-27 Tue 13:42]
Evaluate all strategies, with comparison with baseline.
**** DONE Subtask 3
CLOSED: [2026-01-27 Tue 13:42]
- State "DONE"       from              [2026-01-27 Tue 13:42]
Conclusion of strategies: which are more effective, and which are easy to apply.
*** TODO_NEXT Deliverables
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:44]
