takentaal-amendment v1.0

* TODO_NEXT LLM2FPGA [42%]
:PROPERTIES:
:COOKIE_DATA: todo recursive
:END:
- State "TODO_NEXT"  from              [2026-01-27 Tue 10:54]
LLM2FPGA aims to enable local inference of open-source Large Language Models (LLMs) on FPGAs using a fully open-source toolchain. While LLM inference has been demonstrated on proprietary hardware and software, we are not aware of any widely recognized project running open-source LLMs on FPGAs through a fully open-source EDA (Electronics Design Automation) flow. To fill this gap, the project will produce an HDL implementation of a lightweight open-source LLM, verify it via simulation, and then attempt synthesis and place-and-route on freely supported FPGA devices. By providing a fully open alternative to proprietary and cloud-based LLM inference, LLM2FPGA will offer a transparent, flexible, and privacy-friendly way to run your own LLM on local hardware.
** DONE Survey & candidate selection
CLOSED: [2026-01-27 Tue 10:55]



- State "DONE"       from "TODO_NEXT"  [2026-01-27 Tue 10:55]
- State "TODO_NEXT"  from              [2026-01-27 Tue 10:54]
State of the art review. Although some candidate projects have been identified, to have the big picture of what has been achieved so far, we need to understand 10 to 15 papers/projects, and what can be reused, even finding synergies between papers/projects.



We are lucky that the keywords LLM and FPGA usually give highly relevant results.



The first subtask is desk research. Survey table of 10+ FPGA-LLM papers/repos, answering the following questions:



Openness: Is the code or detailed design public or promised? Open to open-source FPGA tools? Uses open LLMs?



Hardware: Avoid if it needs extra hardware. Check FPGA and open toolchain support.



Design: Note method (RTL/HLS), model size (<10M preferred), proof-of-concept potential, and proprietary tool dependencies.



Second subtask:



The purpose is to identify issues or blockages, not to get each project completely reproduced.



— Can the HDL (SystemVerilog, Verilog) be parsed by Yosys or yosys-slang?



— If HLS is used, can the original C/C++ code be compiled with Vericert or another FOSS HLS tool?



Issues or blockages such as:



— Uses features of HDL (SystemVerilog, VHDL) that are not supported in yosys.



In yosys, Verilog support is more mature than SystemVerilog (with yosys-slang) or VHDL (with ghdl-yosys-plugin)



— Same for HLS



The third subtask:



— Chosen kernel + why



— Any major blockers found in other candidates



— Fallback plan in case current kernel becomes unviable



From now on, we call the chosen kernel the *selected route*.



- Publish survey results based on desk research.

- Research compatibility of potential projects with open source tooling: create a script that clones each repo and runs elaboration with Yosys; logs archived (green, blockages etc)

- Write up and publish results of the research and next steps. (chosen kernel and why + fallback)

** TODO_NEXT End-to-End semantic equivalence of a PyTorch kernel to synthesizable RTL [4/9]
- State "TODO_NEXT"  from              [2026-01-27 Tue 10:54]
*** DONE Title
CLOSED: [2026-01-27 Tue 14:01]
- State "DONE"       from "TODO_NEXT"  [2026-01-27 Tue 14:01]
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:53]
*** DONE Goal:
CLOSED: [2026-01-27 Tue 12:52]
- State "DONE"       from "TODO_NEXT"  [2026-01-27 Tue 12:52]
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:06]
Demonstrate an end-to-end semantic equivalence path by lowering a minimal PyTorch matrix-multiplication kernel through the selected pipeline into synthesizable RTL, verifying that the generated SystemVerilog is accepted by Yosys, produces correct outputs under RTL simulation for fixed inputs, can be integrated with minimal glue logic and programmed into FPGA with correct results.
*** TODO_NEXT Risks and mitigations
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:43]
  PyTorch hard to simulate: it seems well documented https://docs.pytorch.org/executorch/stable/getting-started.html
  Discrepancy between PyTorch and RTL simulation: 
*** TODO_NEXT Subtasks [2/4]
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:06]
**** DONE Subtask 1 consists of:
CLOSED: [2026-01-27 Tue 13:07]
- State "DONE"       from "TODO_NEXT"  [2026-01-27 Tue 13:07]
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:07]
flake.nix with all relevant tooling: torch-MLIR, LLVM MLIR, CIRCT, yosys.

Nix devshell provides all tools used by the pipeline.

Cached derivations for each pipeline stage, so reruns do not recompute earlier stages.

Devshell supports local debug builds for torch-mlir / LLVM / CIRCT / Yosys when Nix debug-symbol packaging is insufficient; instructions included.

**** DONE Subtask 2 consists of:
CLOSED: [2026-01-27 Tue 13:07]
- State "DONE"       from "TODO_NEXT"  [2026-01-27 Tue 13:07]
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:07]
With the same PyTorch module used in 1.c, run a PyTorch simulation with fixed inputs. Run pipeline with that model, simulate resulting SystemVerilog and compare with golden reference.

**** TODO_NEXT Subtask 3 consists of:
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:07]
**** TODO_NEXT Subtask 4 consists of:

- State "TODO_NEXT"  from              [2026-01-27 Tue 12:07]
Ensuring that parsing, formal proof, and simulation can all run via nix develop + make.

Set up a CI pipeline to run nix develop --command make quick (parse, simulate, prove), upload artifacts, and add a status badge to the README. Exit: fresh clone passes automatically.
*** TODO_NEXT Deliverables
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:07]
- nix flake

- Yosys script, Netlist artifact (.il) and logs

- sby script Interface formal harness (ready/valid assertions) passes in sby

- 1-token golden-vector testbench runs in < 5 min with Verilator

- CI smoke test & badge

- Write up of motivation for formal, testbench and how to use kernel

** TODO_NEXT Lowering of small LLM to RTL [2/5]
- State "TODO_NEXT"  from              [2026-01-27 Tue 10:54]
*** DONE Title
CLOSED: [2026-01-27 Tue 12:54]
- State "DONE"       from "TODO_NEXT"  [2026-01-27 Tue 12:54]
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:53]

*** DONE Goal:
CLOSED: [2026-01-27 Tue 14:04]
- State "DONE"       from "TODO_NEXT"  [2026-01-27 Tue 14:04]
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:09]
Test if a small open-source language model (TinyStories-1M) can be lowered from PyTorch to synthesizable RTL using a fully open-source compilation flow.

*** TODO_NEXT Risks and mitigation
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:09]
*** TODO_NEXT Subtasks
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:43]
*** TODO_NEXT Deliverables
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:43]
** TODO_NEXT System integration and hardware demonstration [1/5]
- State "TODO_NEXT"  from              [2026-01-27 Tue 10:54]
*** TODO_NEXT Title
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:53]
*** DONE Goal:
CLOSED: [2026-01-27 Tue 12:59]
- State "DONE"       from "TODO_NEXT"  [2026-01-27 Tue 12:59]
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:09]
Demonstrate that generated RTL can be integrated into a complete FPGA design, synthesized and placed-and-routed, and (if it fits on the target FPGA) executed on real hardware for a fixed input.
*** TODO_NEXT Risks and mitigations
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:10]
*** TODO_NEXT Subtasks
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:10]
*** TODO_NEXT Deliverables
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:43]
** TODO_NEXT Scaling and resource usage analysis [2/5]
- State "TODO_NEXT"  from              [2026-01-27 Tue 10:54]
*** DONE Title
CLOSED: [2026-01-27 Tue 12:54]
- State "DONE"       from "TODO_NEXT"  [2026-01-27 Tue 12:54]
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:53]

*** DONE Goal:
CLOSED: [2026-01-27 Tue 13:00]
- State "DONE"       from "TODO_NEXT"  [2026-01-27 Tue 13:00]
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:43]
Measure how FPGA resource usage scales with model depth and width by mechanically scaling the validated TinyStories-1M architecture.

No new model architectures are introduced.

*** TODO_NEXT Risks and mitigations
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:44]
*** TODO_NEXT Subtasks
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:43]
*** TODO_NEXT Deliverables
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:43]
** TODO_NEXT Resource usage reduction strategies [6/8]
- State "TODO_NEXT"  from              [2026-01-27 Tue 10:55]
*** DONE Title
CLOSED: [2026-01-27 Tue 12:54]
- State "DONE"       from "TODO_NEXT"  [2026-01-27 Tue 12:54]
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:53]

*** DONE Goal:
CLOSED: [2026-01-27 Tue 13:00]
- State "DONE"       from "TODO_NEXT"  [2026-01-27 Tue 13:00]
- State "TODO_NEXT"  from              [2026-01-27 Tue 11:49]
Evaluate whether mitigation techniques can reduce resource usage if scaling results are negative.
*** TODO_NEXT Risks and mitigations
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:44]
*** DONE Subtasks
CLOSED: [2026-01-27 Tue 13:42]
- State "DONE"       from "TODO_NEXT"  [2026-01-27 Tue 13:42]
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:44]
**** DONE Subtask 1
CLOSED: [2026-01-27 Tue 13:42]
- State "DONE"       from "TODO_NEXT"  [2026-01-27 Tue 13:42]
- State "TODO_NEXT"  from              [2026-01-27 Tue 13:35]
Survey 5 to 10 mitigation strategies, at all levels of the pipeline: quantization at PyTorch level, eqmap at verilog level, mlir optimizations etc
**** DONE Subtask 2
CLOSED: [2026-01-27 Tue 13:42]
- State "DONE"       from              [2026-01-27 Tue 13:42]
Evaluate all strategies, with comparison with baseline.
**** DONE Subtask 3
CLOSED: [2026-01-27 Tue 13:42]
- State "DONE"       from              [2026-01-27 Tue 13:42]
Conclusion of strategies: which are more effective, and which are easy to apply.
*** TODO_NEXT Deliverables
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:44]
