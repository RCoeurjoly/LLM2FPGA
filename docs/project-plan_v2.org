takentaal-amendment v1.0

* TODO_NEXT LLM2FPGA [55%]
:PROPERTIES:
:COOKIE_DATA: todo recursive
:END:
- State "TODO_NEXT"  from              [2026-01-27 Tue 10:54]
LLM2FPGA aims to enable local inference of open-source Large Language Models (LLMs) on FPGAs using a fully open-source toolchain. While LLM inference has been demonstrated on proprietary hardware and software, we are not aware of any widely recognized project running open-source LLMs on FPGAs through a fully open-source EDA (Electronics Design Automation) flow. To fill this gap, the project will produce an HDL implementation of a lightweight open-source LLM, verify it via simulation, and then attempt synthesis and place-and-route on freely supported FPGA devices. By providing a fully open alternative to proprietary and cloud-based LLM inference, LLM2FPGA will offer a transparent, flexible, and privacy-friendly way to run your own LLM on local hardware.
** DONE Survey & candidate selection
CLOSED: [2026-02-02 Mon 12:10]
- State "DONE"       from "TODO_NEXT"  [2026-02-02 Mon 12:10]
- State "TODO_NEXT"  from "DONE"       [2026-02-02 Mon 11:24]
- State "DONE"       from "TODO_NEXT"  [2026-01-27 Tue 10:55]
- State "TODO_NEXT"  from              [2026-01-27 Tue 10:54]
State of the art review. Although some candidate projects have been identified, to have the big picture of what has been achieved so far, we need to understand 10 to 15 papers/projects, and what can be reused, even finding synergies between papers/projects.



We are lucky that the keywords LLM and FPGA usually give highly relevant results.



The first subtask is desk research. Survey table of 10+ FPGA-LLM papers/repos, answering the following questions:



Openness: Is the code or detailed design public or promised? Open to open-source FPGA tools? Uses open LLMs?



Hardware: Avoid if it needs extra hardware. Check FPGA and open toolchain support.



Design: Note method (RTL/HLS), model size (<10M preferred), proof-of-concept potential, and proprietary tool dependencies.



Second subtask:



The purpose is to identify issues or blockages, not to get each project completely reproduced.



— Can the HDL (SystemVerilog, Verilog) be parsed by Yosys or yosys-slang?



— If HLS is used, can the original C/C++ code be compiled with Vericert or another FOSS HLS tool?



Issues or blockages such as:



— Uses features of HDL (SystemVerilog, VHDL) that are not supported in yosys.



In yosys, Verilog support is more mature than SystemVerilog (with yosys-slang) or VHDL (with ghdl-yosys-plugin)



— Same for HLS



The third subtask:



— Chosen kernel + why



— Any major blockers found in other candidates



— Fallback plan in case current kernel becomes unviable



From now on, we call the chosen kernel the *selected route*.



- Publish survey results based on desk research.

- Research compatibility of potential projects with open source tooling: create a script that clones each repo and runs elaboration with Yosys; logs archived (green, blockages etc)

- Write up and publish results of the research and next steps. (chosen kernel and why + fallback)

** DONE End-to-End semantic equivalence of a PyTorch kernel to synthesizable RTL [10/10]
CLOSED: [2026-02-02 Mon 14:35]
- State "DONE"       from "TODO_NEXT"  [2026-02-02 Mon 14:35]
- State "TODO_NEXT"  from "DONE"       [2026-02-02 Mon 11:25]
- State "DONE"       from "TODO_NEXT"  [2026-01-28 Wed 11:37]
- State "TODO_NEXT"  from              [2026-01-27 Tue 10:54]
*** DONE Title
CLOSED: [2026-01-27 Tue 14:01]
- State "DONE"       from "TODO_NEXT"  [2026-01-27 Tue 14:01]
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:53]
*** DONE Goal:
CLOSED: [2026-01-27 Tue 12:52]
- State "DONE"       from "TODO_NEXT"  [2026-01-27 Tue 12:52]
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:06]
Demonstrate that the selected pipeline can lower a minimal PyTorch kernel to synthesizable RTL, integrate it into a complete FPGA top-level, generate a bitstream, and run a fixed test vector on real hardware with outputs matching the PyTorch reference.
*** DONE Risks and mitigations
CLOSED: [2026-01-28 Wed 11:37]
- State "DONE"       from "TODO_NEXT"  [2026-01-28 Wed 11:37]
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:43]
  PyTorch hard to simulate: it seems well documented https://docs.pytorch.org/executorch/stable/getting-started.html
  Discrepancy between PyTorch and RTL simulation: simulate each MLIR stage with original PyTorch, to isolate the pass that creates discrepancy
*** DONE Subtasks [5/5]
CLOSED: [2026-01-28 Wed 11:37]
- State "DONE"       from "TODO_NEXT"  [2026-01-28 Wed 11:37]
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:06]
**** DONE Subtask 1 consists of:
CLOSED: [2026-01-27 Tue 13:07]
- State "DONE"       from "TODO_NEXT"  [2026-01-27 Tue 13:07]
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:07]
flake.nix with all relevant tooling: torch-MLIR, LLVM MLIR, CIRCT, yosys.

Nix devshell provides all tools used by the pipeline.

Cached derivations for each pipeline stage, so reruns do not recompute earlier stages.

Also, for each upstream tool, support a build with debug symbols. Needed for debugging issues with tooling.

**** DONE Subtask 2 consists of:
CLOSED: [2026-01-27 Tue 13:07]
- State "DONE"       from "TODO_NEXT"  [2026-01-27 Tue 13:07]
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:07]
With the same PyTorch module used in 1.c, run a PyTorch simulation with fixed inputs. Run pipeline with that model, simulate resulting SystemVerilog and compare with golden reference.
**** DONE Subtask 3 consists of:
CLOSED: [2026-01-27 Tue 16:31]
- State "DONE"       from "TODO_NEXT"  [2026-01-27 Tue 16:31]
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:07]
  Yosys ingestion + RTLIL netlist gate

Artifact: matmul.il produced by Yosys from matmul.sv.

Yosys completes elaboration and emits RTLIL without fatal errors.

**** DONE Subtask 4 consists of:
CLOSED: [2026-01-27 Tue 16:32]
- State "DONE"       from "TODO_NEXT"  [2026-01-27 Tue 16:32]
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:07]
Glue RTL for interface, Bitstream generation and testing
Think of the simplest way to interface with the host computer, generate bitstream of glue RTL + model RTL, test results are equivalent to golden reference.

Read and reuse previous work with this board:
https://www.cnblogs.com/ruidongwu/p/18564807

https://x.com/enjoy_digital/status/1924910401176719375

https://www.controlpaths.com/2025/05/18/kintex7-accelerator/
**** DONE Subtask 5 consists of:
CLOSED: [2026-01-28 Wed 11:17]
- State "DONE"       from "TODO_NEXT"  [2026-01-28 Wed 11:17]
- State "TODO_NEXT"  from "DONE"       [2026-01-28 Wed 11:17]
- State "DONE"       from "TODO_NEXT"  [2026-01-27 Tue 16:32]
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:07]
Report and demo of results
*** DONE Deliverables
CLOSED: [2026-01-28 Wed 11:37]
- State "DONE"       from "TODO_NEXT"  [2026-01-28 Wed 11:37]
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:07]
- nix flake and matmul.sv from executing it

- PyTorch simulation trace, systemverilog testbench and their comparison

- matmul.il and resource usage report with "yosys stat"

- FPGA integration + bring-up
  
- Write up of results, and video demo if succesful

** DONE Lowering of small LLM to RTL [10/10]
CLOSED: [2026-02-02 Mon 18:52]
- State "DONE"       from "TODO_NEXT"  [2026-02-02 Mon 18:52]
- State "TODO_NEXT"  from "DONE"       [2026-02-02 Mon 11:25]
- State "DONE"       from "TODO_NEXT"  [2026-01-29 Thu 20:28]
- State "TODO_NEXT"  from              [2026-01-27 Tue 10:54]
*** DONE Title
CLOSED: [2026-02-02 Mon 18:21]
- State "DONE"       from "TODO_NEXT"  [2026-02-02 Mon 18:21]
- State "TODO_NEXT"  from "DONE"       [2026-02-02 Mon 14:35]
- State "DONE"       from "TODO_NEXT"  [2026-01-27 Tue 12:54]
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:53]
*** DONE Goal:
CLOSED: [2026-02-02 Mon 18:21]
- State "DONE"       from "TODO_NEXT"  [2026-02-02 Mon 18:21]
- State "TODO_NEXT"  from "DONE"       [2026-02-02 Mon 14:35]
- State "DONE"       from "TODO_NEXT"  [2026-01-27 Tue 14:04]
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:09]
Test if a small open-source language model (TinyStories-1M) can be lowered from PyTorch to synthesizable RTL using a fully open-source compilation flow.

In this task we move from small matmul module to smallest available LLM.
This task establishes existence of a valid lowering path only; scalability and hardware execution are out of scope, for later tasks.

The succesful result is an unintegrated RTL netlist of the model (RTLIL or Verilog/SystemVerilog) and synthesis resource estimates, without stubbing operators.

Otherwise, bottleneck report identifying unsupported operators, failing passes, or any other error in the toolchain.

Functional equivalence to PyTorch is not evaluated in this task; only structural synthesizability is established. Semantic validation is addressed in the subsequent hardware validation task.
*** DONE Risks and mitigation
CLOSED: [2026-02-02 Mon 18:46]
- State "DONE"       from              [2026-02-02 Mon 18:46]
Risks:

Unsupported MLIR operations found during lowering.

Invalid, non-synthesizable, or structurally incorrect RTL emitted by CIRCT.

Toolchain pass interactions leading to verifier failures or fatal errors at stage boundaries.

Mitigations:
Use -verify-each for each MLIR stage.

For failures, isolate minimal reproducing cases using mlir-reduce and archive them.

If necessary, adjust pass ordering. Final success must not rely on operator stubbing or blackboxes.

MLIR debugging docs:
https://mlir.llvm.org/getting_started/Debugging/
*** DONE Subtasks
CLOSED: [2026-02-02 Mon 18:52]
- State "DONE"       from "TODO_NEXT"  [2026-02-02 Mon 18:52]
- State "TODO_NEXT"  from "DONE"       [2026-02-02 Mon 14:35]
- State "DONE"       from "TODO_NEXT"  [2026-01-29 Thu 20:24]
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:43]
**** DONE Subtask 1
CLOSED: [2026-01-28 Wed 11:51]
- State "DONE"       from "TODO_NEXT"  [2026-01-28 Wed 11:51]
- State "TODO_NEXT"  from              [2026-01-28 Wed 11:49]
Frozen TinyStories-1M artifact
**** DONE Subtask 2
CLOSED: [2026-01-28 Wed 12:58]
- State "DONE"       from              [2026-01-28 Wed 12:58]
tiny_stories_1m.mlir, just before consumption by CIRCT
If a blocker exists, a reduced reproducer (mlir-reduce or minimized export input) is committed or archived.
The MLIR verifier passes at this boundary (-verify-each clean at this stage).
**** DONE Subtask 3
CLOSED: [2026-01-28 Wed 13:07]
- State "DONE"       from              [2026-01-28 Wed 13:07]
tiny_stories_1m.sv, generated by CIRCT
Generated RTL is structurally sanity-checked (at minimum: parsable by Yosys front-end in the pinned environment).
If a blocker exists, a reduced reproducer (mlir-reduce or minimized export input) is committed or archived.
**** DONE Subtask 4
CLOSED: [2026-01-28 Wed 15:38]
- State "DONE"       from "TODO_NEXT"  [2026-01-28 Wed 15:38]
- State "TODO_NEXT"  from              [2026-01-28 Wed 13:07]
  Artifact: tinystories_1m.il produced by Yosys from tinystories_1m.sv.
  Yosys completes elaboration and emits RTLIL without fatal errors.
**** DONE Subtask 5
CLOSED: [2026-01-29 Thu 20:23]
- State "DONE"       from "TODO_NEXT"  [2026-01-29 Thu 20:23]
- State "TODO_NEXT"  from              [2026-01-28 Wed 15:38]
  Artifact: resource utilization report (Yosys stat) generated from the .il/design.

Bottleneck report: unsupported operators encountered, failing passes, required stubs/workarounds, and/or any other error. Includes minimized reproducers.

*** DONE Deliverables
CLOSED: [2026-02-02 Mon 18:52]
- State "DONE"       from "TODO_NEXT"  [2026-02-02 Mon 18:52]
- State "TODO_NEXT"  from "DONE"       [2026-02-02 Mon 14:35]
- State "DONE"       from "TODO_NEXT"  [2026-01-29 Thu 20:23]
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:43]
  - TinyStories-1M PyTorch model
  - tiny_stories_1m.mlir, just before consumption by CIRCT
  - tiny_stories_1m.sv, generated by CIRCT
  - tiny_stories_1m.il, generated by yosys
  - synthesis resource report + bottleneck report
** TODO_NEXT FPGA integration and hardware validation [0/10]
- State "TODO_NEXT"  from "DONE"       [2026-02-02 Mon 11:25]
- State "DONE"       from "TODO_NEXT"  [2026-01-30 Fri 00:22]
- State "TODO_NEXT"  from              [2026-01-27 Tue 10:54]
*** TODO_NEXT Title
- State "TODO_NEXT"  from "DONE"       [2026-02-02 Mon 14:35]
- State "DONE"       from "TODO_NEXT"  [2026-01-27 Tue 16:07]
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:53]
*** TODO_NEXT Goal:
- State "TODO_NEXT"  from "DONE"       [2026-02-02 Mon 14:35]
- State "DONE"       from "TODO_NEXT"  [2026-01-27 Tue 16:07]
- State "TODO_NEXT"  from "DONE"       [2026-01-27 Tue 16:02]
- State "DONE"       from "TODO_NEXT"  [2026-01-27 Tue 12:59]
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:09]
Demonstrate that the generated model RTL can coexist with minimal glue logic and be processed through a full FPGA synthesis and place-and-route flow.
Demonstrate execution of the synthesized design on FPGA hardware.

The target board is YPCB-00338-1P1.
*** TODO_NEXT Risks and mitigations
- State "TODO_NEXT"  from "DONE"       [2026-02-02 Mon 14:35]
- State "DONE"       from "TODO_NEXT"  [2026-01-29 Thu 22:13]
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:10]
Non-idiomatic or impractical auto-generated interfaces

Hard to find where errors come from between different steps/passes.

Mitigation consists of treating the PyTorch model as the single source of truth and introducing reference checks at every stage of the pipeline. For each MLIR, and RTL simulation.
*** TODO_NEXT Subtasks
- State "TODO_NEXT"  from "DONE"       [2026-02-02 Mon 14:35]
- State "DONE"       from "TODO_NEXT"  [2026-01-30 Fri 00:21]
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:10]
**** TODO_NEXT Subtask 1
- State "TODO_NEXT"  from              [2026-02-02 Mon 14:37]
Define and freeze the host-facing hardware contract

Scope

Define the minimal, execution-oriented interface between host and model RTL.

Activities

Specify data/control protocol (inputs, outputs, handshakes, reset, start/done).

Decide clocking/reset assumptions.

Write a short, precise interface spec.

Artifacts

Interface specification document.

Interface signals reflected in top-level RTL stub.

Kill criterion

Interface is fully specified and stable enough to write glue RTL against.
**** TODO_NEXT Subtask 2
- State "TODO_NEXT"  from              [2026-02-02 Mon 14:37]
Top-level RTL integration (model + glue)

Scope

Produce a single synthesizable top-level design.

Activities

Write glue RTL implementing the frozen contract.

Instantiate model RTL.

Resolve clocks, resets, widths, and data marshaling.

Artifacts

Top-level SystemVerilog.

Minimal simulation testbench exercising the interface.

Kill criterion

Yosys elaborates the full design without errors.
**** TODO_NEXT Subtask 3
- State "TODO_NEXT"  from              [2026-02-02 Mon 14:37]
FPGA synthesis and place-and-route

Scope

Validate FPGA feasibility independent of hardware execution.

Activities

Run synthesis, mapping, and place-and-route for YPCB-00338-1P1.

Generate bitstream if possible; otherwise stop at PnR.

Collect utilization and timing reports.

Artifacts

Bitstream or PnR report.

FPGA utilization summary.

Kill criterion

Place-and-route completes for the target FPGA.
**** TODO_NEXT Subtask 4
- State "TODO_NEXT"  from              [2026-02-02 Mon 14:37]
Board bring-up and execution

Scope

Demonstrate that the design runs on real hardware.

Activities

Program the FPGA.

Establish host communication.

Execute a fixed, known input through the design.

Capture outputs (UART logs, traces, buffers, etc.).

Artifacts

Programming logs.

Execution traces / photos / captures.

Kill criterion

FPGA executes deterministically and produces stable outputs.
**** TODO_NEXT Subtask 5
- State "TODO_NEXT"  from              [2026-02-02 Mon 14:37]
Hardware vs PyTorch equivalence check

Scope

Validate semantic correctness of hardware execution.

Activities

Define fixed TinyStories-1M input.

Generate PyTorch reference output.

Compare FPGA output to reference (exact or tolerance-based).

Artifacts

Reference output.

Comparison report.

Short demonstration write-up.

Kill criterion

FPGA output matches PyTorch reference for the fixed input.
*** TODO_NEXT Deliverables
- State "TODO_NEXT"  from "DONE"       [2026-02-02 Mon 14:35]
- State "DONE"       from "TODO_NEXT"  [2026-01-30 Fri 00:22]
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:43]
- Interface specification document.
- Top-level SystemVerilog.
- Bitstream or PnR report.
- Programming logs.
- Reference output, Comparison report, Short demonstration write-up.
** DONE Scaling and resource usage analysis [5/8]
CLOSED: [2026-02-02 Mon 18:19]
- State "DONE"       from "TODO_NEXT"  [2026-02-02 Mon 18:19]
- State "TODO_NEXT"  from "DONE"       [2026-02-02 Mon 11:25]
- State "DONE"       from "TODO_NEXT"  [2026-01-30 Fri 00:24]
- State "TODO_NEXT"  from              [2026-01-27 Tue 10:54]
*** DONE Title
CLOSED: [2026-02-02 Mon 18:19]
- State "DONE"       from "TODO_NEXT"  [2026-02-02 Mon 18:19]
- State "TODO_NEXT"  from "DONE"       [2026-02-02 Mon 14:35]
- State "DONE"       from "TODO_NEXT"  [2026-01-27 Tue 12:54]
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:53]

*** DONE Goal:
CLOSED: [2026-02-02 Mon 18:19]
- State "DONE"       from "TODO_NEXT"  [2026-02-02 Mon 18:19]
- State "TODO_NEXT"  from "DONE"       [2026-02-02 Mon 14:35]
- State "DONE"       from "TODO_NEXT"  [2026-01-27 Tue 13:00]
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:43]
evaluate how resource usage and pipeline robustness change across the published TinyStories model family (1M/3M/8M/28M/33M, excluding 1Layer-21M). https://huggingface.co/datasets/roneneldan/TinyStories

No new model architectures are introduced.

Success would be: a reproducible per-model pipeline results matrix (stage pass/fail, compile time, resource/timing where available) plus a scaling report for the TinyStories family.

*** DONE Risks and mitigations
CLOSED: [2026-02-02 Mon 18:19]
- State "DONE"       from "TODO_NEXT"  [2026-02-02 Mon 18:19]
- State "TODO_NEXT"  from "DONE"       [2026-02-02 Mon 14:36]
- State "DONE"       from "TODO_NEXT"  [2026-01-29 Thu 22:09]
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:44]
Pipeline does not work for larger models.
Mitigation: reduce those cases with mlir-reduce

Compile time or memory usage of the toolchain becomes prohibitive.
Mitigation: record wall-clock time and peak memory usage for each pipeline stage. If a stage fails due to resource exhaustion, get the smallest failing reproducer.
*** DONE Subtasks
CLOSED: [2026-02-02 Mon 18:19]
- State "DONE"       from "TODO_NEXT"  [2026-02-02 Mon 18:19]
- State "TODO_NEXT"  from "DONE"       [2026-02-02 Mon 14:36]
- State "DONE"       from "TODO_NEXT"  [2026-01-30 Fri 00:24]
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:43]
**** TODO_NEXT Subtask 1 consists of
- State "TODO_NEXT"  from              [2026-02-02 Mon 14:37]
  Model inventory and metadata extraction
For each model: parameter count, layers, heads, embedding, vocab, etc.
**** TODO_NEXT Subtask 2 consists of
- State "TODO_NEXT"  from              [2026-02-02 Mon 14:37]
Create nix derivations for each model.
**** TODO_NEXT Subtask 3 consists of
- State "TODO_NEXT"  from              [2026-02-02 Mon 14:37]
Generate scaling plots of resource usage (LUT/FF/BRAM/DSP), compile time, and (if available) Fmax vs parameter count and selected hyperparameters. Fit simple models (e.g. linear or polynomial in parameter count) and report observed trends.

Note: these trends would apply only to TinyStories, not to other model families.
*** DONE Deliverables
CLOSED: [2026-02-02 Mon 18:19]
- State "DONE"       from "TODO_NEXT"  [2026-02-02 Mon 18:19]
- State "TODO_NEXT"  from "DONE"       [2026-02-02 Mon 14:36]
- State "DONE"       from "TODO_NEXT"  [2026-01-30 Fri 00:23]
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:43]
- Model inventory table (hyperparams + param count).
- Create nix derivations at different scaling points.
- Per-model pipeline results matrix (stage pass/fail, compile time, peak memory, resource usage, Fmax if available). Scaling plots (resource usage, compile time, Fmax vs parameter count). Bottleneck summary identifying the first failing stage per model and root cause.

** TODO_NEXT Resource usage reduction strategies [0/8]
- State "TODO_NEXT"  from "DONE"       [2026-02-02 Mon 11:25]
- State "DONE"       from "TODO_NEXT"  [2026-01-29 Thu 22:01]
- State "TODO_NEXT"  from              [2026-01-27 Tue 10:55]
*** TODO_NEXT Title
- State "TODO_NEXT"  from "DONE"       [2026-02-02 Mon 14:36]
- State "DONE"       from "TODO_NEXT"  [2026-01-27 Tue 12:54]
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:53]

*** TODO_NEXT Goal:
- State "TODO_NEXT"  from "DONE"       [2026-02-02 Mon 14:36]
- State "DONE"       from "TODO_NEXT"  [2026-01-27 Tue 13:00]
- State "TODO_NEXT"  from              [2026-01-27 Tue 11:49]
Evaluate whether mitigation techniques can reduce resource usage if the scaling task shows that larger models do not fit the target device.
Baseline is the largest successfully lowered model from the scaling task.
*** TODO_NEXT Risks and mitigations
- State "TODO_NEXT"  from "DONE"       [2026-02-02 Mon 14:36]
- State "DONE"       from "TODO_NEXT"  [2026-01-29 Thu 22:01]
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:44]
Some strategy breaks the pipeline.
No resource reduction.

Mitigation: testing and comparing several strategies, and documenting even negative or neutral results.
*** TODO_NEXT Subtasks
- State "TODO_NEXT"  from "DONE"       [2026-02-02 Mon 14:36]
- State "DONE"       from "TODO_NEXT"  [2026-01-29 Thu 21:56]
- State "TODO_NEXT"  from "DONE"       [2026-01-29 Thu 21:56]
- State "DONE"       from "TODO_NEXT"  [2026-01-27 Tue 13:42]
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:44]
**** TODO_NEXT Subtask 1
- State "TODO_NEXT"  from "DONE"       [2026-02-02 Mon 14:38]
- State "DONE"       from "TODO_NEXT"  [2026-01-29 Thu 21:56]
- State "TODO_NEXT"  from "DONE"       [2026-01-29 Thu 21:56]
- State "DONE"       from "TODO_NEXT"  [2026-01-27 Tue 13:42]
- State "TODO_NEXT"  from              [2026-01-27 Tue 13:35]
Survey 5 to 10 mitigation strategies, at model-level, MLIR, and RTL: quantization at PyTorch level, eqmap at verilog level, mlir optimizations etc
**** TODO_NEXT Subtask 2
- State "TODO_NEXT"  from "DONE"       [2026-02-02 Mon 14:38]
- State "DONE"       from              [2026-01-27 Tue 13:42]
Evaluate all strategies, with comparison with baseline.

For each strategy, record:

Delta LUT/FF/BRAM/DSP

Delta max clock frequency

Delta toolchain runtime + peak memory

Each strategy must work without blackboxes or stubs.
**** TODO_NEXT Subtask 3
- State "TODO_NEXT"  from "DONE"       [2026-02-02 Mon 14:38]
- State "DONE"       from              [2026-01-27 Tue 13:42]
Conclusion of strategies: which are more effective, and which are easy to apply.
*** TODO_NEXT Deliverables
- State "TODO_NEXT"  from "DONE"       [2026-02-02 Mon 14:36]
- State "DONE"       from "TODO_NEXT"  [2026-01-29 Thu 22:01]
- State "TODO_NEXT"  from              [2026-01-27 Tue 12:44]
- resource_usage_reduction_strategies.org
- For each strategy, scripts for usage, and before and after resource utilization
- Strategy comparison table with all deltas and viability status.
  
